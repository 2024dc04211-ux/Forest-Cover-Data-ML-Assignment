{"cells":[{"cell_type":"markdown","id":"0876b8da","metadata":{"id":"0876b8da"},"source":["# Final Exploratory Data Analysis (EDA)\n","Dataset: covtype.csv"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"YS474DzxT0Ms"},"id":"YS474DzxT0Ms","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"fa333f97","metadata":{"id":"fa333f97"},"outputs":[],"source":["\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","sns.set()\n","plt.style.use(\"default\")\n","\n","df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/covtype.csv\")\n","df.head()\n","df=df.head(100000)"]},{"cell_type":"code","execution_count":null,"id":"1577feaf","metadata":{"id":"1577feaf"},"outputs":[],"source":["df.shape"]},{"cell_type":"code","execution_count":null,"id":"6522d357","metadata":{"id":"6522d357","collapsed":true},"outputs":[],"source":["df.info()"]},{"cell_type":"code","execution_count":null,"id":"8ae25919","metadata":{"id":"8ae25919","collapsed":true},"outputs":[],"source":["df.describe()"]},{"cell_type":"code","execution_count":null,"id":"282aae55","metadata":{"id":"282aae55","collapsed":true},"outputs":[],"source":["df.isnull().sum()"]},{"cell_type":"code","execution_count":null,"id":"033332bc","metadata":{"id":"033332bc"},"outputs":[],"source":["df.duplicated().sum()"]},{"cell_type":"code","execution_count":null,"id":"97a10be4","metadata":{"id":"97a10be4"},"outputs":[],"source":["\n","df = df.drop_duplicates()\n"]},{"cell_type":"code","execution_count":null,"id":"97914cce","metadata":{"id":"97914cce","collapsed":true},"outputs":[],"source":["\n","df[\"Cover_Type\"].value_counts()\n"]},{"cell_type":"code","execution_count":null,"id":"a24f7184","metadata":{"id":"a24f7184"},"outputs":[],"source":["\n","plt.figure(figsize=(6,4))\n","sns.countplot(x=\"Cover_Type\", data=df)\n","plt.title(\"Distribution of Cover Types\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"6a1475c5","metadata":{"id":"6a1475c5"},"outputs":[],"source":["\n","num_cols = df.select_dtypes(include=np.number).columns\n","df[num_cols].hist(figsize=(15,12), bins=30)\n","plt.suptitle(\"Histogram of Numerical Features\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"bba1641a","metadata":{"id":"bba1641a"},"outputs":[],"source":["\n","plt.figure(figsize=(14,10))\n","corr = df.corr()\n","sns.heatmap(corr, cmap=\"coolwarm\", linewidths=0.5)\n","plt.title(\"Correlation Heatmap\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"788c061c","metadata":{"id":"788c061c"},"outputs":[],"source":["\n","plt.figure(figsize=(6,4))\n","sns.boxplot(x=\"Cover_Type\", y=\"Elevation\", data=df)\n","plt.title(\"Elevation vs Cover Type\")\n","plt.show()\n"]},{"cell_type":"code","source":["corr_with_target = df.corr()[\"Cover_Type\"].sort_values(ascending=False)\n","\n","plt.figure(figsize=(8,6))\n","corr_with_target.drop(\"Cover_Type\").plot(kind=\"bar\")\n","plt.title(\"Correlation of Features with Cover_Type\")\n","plt.ylabel(\"Correlation value\")\n","plt.xlabel(\"Features\")\n","plt.show()"],"metadata":{"id":"zvtxqyYUUzul"},"id":"zvtxqyYUUzul","execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(6,10))\n","sns.heatmap(df.corr()[[\"Cover_Type\"]], annot=True, cmap=\"coolwarm\")\n","plt.title(\"Correlation of Features with Cover_Type\")\n","plt.show()"],"metadata":{"id":"qWzzjyxAVDcs"},"id":"qWzzjyxAVDcs","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","def basic_info(df):\n","    print(df.info())\n","    print(df.describe())\n","\n","def check_missing(df):\n","    print(df.isnull().sum())\n","\n","def plot_target_distribution(df, target):\n","    sns.countplot(x=target, data=df)\n","    plt.title(\"Target Distribution\")\n","    plt.show()\n","\n","def correlation_plot(df):\n","    plt.figure(figsize=(10, 6))\n","    sns.heatmap(df.corr(), cmap=\"coolwarm\", annot=False)\n","    plt.title(\"Correlation Heatmap\")\n","    plt.show()\n"],"metadata":{"id":"j4P-l7-4dQoI"},"execution_count":null,"outputs":[],"id":"j4P-l7-4dQoI"},{"cell_type":"code","source":["def numerical_summary(df):\n","    num_df = df.select_dtypes(include=np.number)\n","    return num_df.describe()\n","\n","def categorical_summary(df):\n","    cat_df = df.select_dtypes(exclude=np.number)\n","    return cat_df.describe()\n","\n","def skewness(df):\n","    return df.select_dtypes(include=np.number).skew()\n","def target_distribution(df, target):\n","    print(df[target].value_counts())\n","    plt.figure(figsize=(6,4))\n","    sns.countplot(x=df[target])\n","    plt.title(\"Target Distribution\")\n","    plt.show()\n","def boxplots(df):\n","    num_cols = df.select_dtypes(include=np.number).columns\n","    for col in num_cols:\n","        plt.figure(figsize=(5,3))\n","        sns.boxplot(x=df[col])\n","        plt.title(col)\n","        sns.despine()\n","        plt.show()\n","def binary_feature_counts(df, columns, title):\n","    counts = df[columns].sum().sort_values(ascending=False)\n","    plt.figure(figsize=(10,5))\n","    counts.plot(kind=\"bar\")\n","    plt.title(title)\n","    plt.show()\n","    return counts\n","#binary_feature_counts(data, wilderness_cols, \"Wilderness Area Count\")\n","#binary_feature_counts(data, soil_cols, \"Soil Type Count\")\n","def violin_plots(df, features, target):\n","    for col in features:\n","        plt.figure(figsize=(6,4))\n","        sns.violinplot(x=target, y=col, data=df)\n","        plt.title(col)\n","        plt.show()\n","\n","def violin(data):\n","  # plot bg\n","  # Extracting all numerical features from data\n","  num_fea = data.iloc[:, :10]\n","\n","  # extracting all binary features from data\n","  binary_fea = data.iloc[:, 10:-1]\n","\n","  # Splitting\n","  Wild_data, Soil_data = binary_fea.iloc[:,:4], binary_fea.iloc[:,4:]\n","  sns.set_style(\"darkgrid\", {'grid.color': '.1'})\n","\n","  # setting target variable\n","  target = data['Cover_Type']\n","  # features to be compared with target variable\n","  features = Wild_data.columns\n","\n","\n","  # loop for plotting Violin Plot for each features in the data\n","  for i in range(0, len(features)):\n","\n","      #figure size\n","      plt.subplots(figsize=(13, 9))\n","\n","      # Plot violin for i feature for every class in target\n","      sns.violinplot(data = Wild_data, x=target, y = features[i])\n","\n","      # x-axis label size\n","      plt.xticks(size = 15)\n","      # y-axis label size\n","      plt.yticks(size = 16)\n","\n","      # Horizontal axis Label\n","      plt.xlabel('Forest Cover Types', size = 17)\n","      # Vertical axis Label\n","      plt.ylabel(features[i], size = 17)\n","\n","      # display plot\n","      plt.show()"],"metadata":{"id":"LHeOVUF3ruRE"},"id":"LHeOVUF3ruRE","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lMOkPhozulKC"},"id":"lMOkPhozulKC","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","\n","def feature_importance(df, target, model=None):\n","    X = df.drop(target, axis=1)\n","    y = df[target]\n","\n","    if model is None:\n","        model = RandomForestClassifier(n_jobs=-1, random_state=42)\n","\n","    model.fit(X, y)\n","    imp = pd.DataFrame({\n","        \"Feature\": X.columns,\n","        \"Importance\": model.feature_importances_\n","    }).sort_values(by=\"Importance\", ascending=False)\n","\n","    return imp\n"],"metadata":{"id":"G7TqbVcmr_1c"},"id":"G7TqbVcmr_1c","execution_count":null,"outputs":[]},{"cell_type":"code","source":["data=df\n","\n","numerical_summary(data)\n","\n","skewness(data)\n","\n","target_distribution(data, \"Cover_Type\")\n","\n","boxplots(data)\n","\n","importance = feature_importance(data, \"Cover_Type\")\n","importance.head(10)\n","\n","#violin_plots(df, features, target)\n","violin(df)\n","'''\n","X_train, X_test, y_train, y_test = scale_and_split(data, \"Cover_Type\")\n","\n","from sklearn.ensemble import RandomForestClassifier\n","model_evaluation(RandomForestClassifier(n_jobs=-1), X_train, X_test, y_train, y_test)\n","'''"],"metadata":{"id":"7U7nXWp2sH7u"},"id":"7U7nXWp2sH7u","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# importing model for feature importance\n","from sklearn.ensemble import ExtraTreesClassifier\n","\n","# passing the model\n","model = ExtraTreesClassifier(random_state = 53)\n","\n","# feeding all our features to var 'X'\n","X = df.iloc[:,:-1]\n","# feeding our target variable to var 'y'\n","y = df['Cover_Type']\n","\n","# training the model\n","model.fit(X, y)\n","\n","# extracting feature importance from model and making a dataframe of it in descending order\n","ETC_feature_importances = pd.DataFrame(model.feature_importances_, index = X.columns, columns=['ETC']).sort_values('ETC', ascending=False)\n","\n","# removing traces of this model\n","model = None\n","\n","# show top 10 features\n","ETC_feature_importances.head(10)"],"metadata":{"id":"-EwDWEX8tNr-"},"id":"-EwDWEX8tNr-","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# importing model for feature importance\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# passing the model\n","model = RandomForestClassifier(random_state = 53)\n","\n","# training the model\n","model.fit(X, y)\n","\n","# extracting feature importance from model and making a dataframe of it in descending order\n","RFC_feature_importances = pd.DataFrame(model.feature_importances_, index = X.columns, columns=['RFC']).sort_values('RFC', ascending=False)\n","\n","# removing traces of this model\n","model = None\n","\n","# show top 10 features\n","RFC_feature_importances.head(10)"],"metadata":{"id":"pIky_8yztcjX"},"id":"pIky_8yztcjX","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# importing model for feature importance\n","from sklearn.ensemble import AdaBoostClassifier\n","\n","# passing the model\n","model = AdaBoostClassifier(random_state = 53)\n","\n","model.fit(X, y)\n","\n","# extracting feature importance from model and making a dataframe of it in descending order\n","ADB_feature_importances = pd.DataFrame(model.feature_importances_, index = X.columns, columns=['ADB']).sort_values('ADB', ascending=False)\n","\n","# removing traces of this model\n","model = None\n","\n","ADB_feature_importances.head(10)"],"metadata":{"id":"qz37WNfdtfkm"},"id":"qz37WNfdtfkm","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# importing model for feature importance\n","from sklearn.ensemble import GradientBoostingClassifier\n","\n","# passing the model\n","model = GradientBoostingClassifier(random_state = 53)\n","\n","# training the model\n","model.fit(X, y)\n","\n","# extracting feature importance from model and making a dataframe of it in descending order\n","GBC_feature_importances = pd.DataFrame(model.feature_importances_, index = X.columns, columns=['GBC']).sort_values('GBC', ascending=False)\n","\n","# removing traces of this model\n","model = None\n","\n","# show top 10 features\n","GBC_feature_importances.head(10)"],"metadata":{"id":"ayMYBKyktjiO"},"id":"ayMYBKyktjiO","execution_count":null,"outputs":[]},{"cell_type":"code","source":["## feeding top 20 features in a variable as dataframe including target variable\n","\n","## AdaBoost Sample\n","#sample = data[['Wilderness_Area4', 'Elevation','Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology','Aspect','Wilderness_Area4', 'Soil_Type4', 'Soil_Type10' 'Cover_Type']]\n","\n","sample = df[['Elevation','Horizontal_Distance_To_Roadways','Horizontal_Distance_To_Fire_Points','Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology','Aspect','Wilderness_Area4',\n","            'Hillshade_Noon','Hillshade_3pm','Hillshade_9am','Slope','Soil_Type22','Soil_Type10','Soil_Type4','Soil_Type34','Soil_Type34','Wilderness_Area3','Soil_Type12',\n","            'Soil_Type2','Wilderness_Area1', 'Cover_Type']]"],"metadata":{"id":"d5kT63AIt6Ap"},"id":"d5kT63AIt6Ap","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","# feeding sample features to var 'X'\n","X = sample.iloc[:,:-1]\n","# feeding our target variable to var 'y'\n","y = sample['Cover_Type']\n","\n","#X = df.drop(\"Cover_Type\", axis=1)\n","#y = df[\"Cover_Type\"]\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.25, random_state=42, stratify=y\n",")\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","print(\"Train shape:\", X_train.shape)\n","print(\"Test shape:\", X_test.shape)\n"],"metadata":{"id":"dEz6Bbv2ymkq"},"id":"dEz6Bbv2ymkq","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.ensemble import RandomForestClassifier\n","\n","from xgboost import XGBClassifier\n","\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score,\n","    f1_score, matthews_corrcoef, roc_auc_score,\n","    confusion_matrix, classification_report\n",")\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","\n","models = {\n","    \"Logistic Regression\": LogisticRegression(max_iter=2000, n_jobs=-1),\n","    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n","    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n","    \"Naive Bayes\": GaussianNB(),\n","    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n","    \"XGBoost\": XGBClassifier(\n","        objective=\"multi:softprob\",\n","        num_class=len(y.unique()),\n","        eval_metric=\"mlogloss\",\n","        random_state=42,\n","        n_estimators=100,\n","        learning_rate=0.1\n","    )\n","}\n"],"metadata":{"id":"Hk_aplHe0KpW"},"id":"Hk_aplHe0KpW","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate_model(name, model, Xtr, Xte, ytr, yte):\n","    model.fit(Xtr, ytr)\n","    y_pred = model.predict(Xte)\n","    y_prob = model.predict_proba(Xte)\n","\n","    acc = accuracy_score(yte, y_pred)\n","    prec = precision_score(yte, y_pred, average=\"weighted\")\n","    rec = recall_score(yte, y_pred, average=\"weighted\")\n","    f1 = f1_score(yte, y_pred, average=\"weighted\")\n","    mcc = matthews_corrcoef(yte, y_pred)\n","    auc = roc_auc_score(yte, y_prob, multi_class=\"ovr\")\n","\n","    print(f\"\\n{name}\")\n","    print(classification_report(yte, y_pred))\n","\n","    '''\n","    cm = confusion_matrix(y_test, y_pred)\n","    plt.figure(figsize=(6,4))\n","    sns.heatmap(cm, annot=False, cmap=\"Blues\")\n","    plt.title(f\"Confusion Matrix - {name}\")\n","    plt.xlabel(\"Predicted\")\n","    plt.ylabel(\"Actual\")\n","    plt.show()\n","    '''\n","    return [name, acc, auc, prec, rec, f1, mcc]"],"metadata":{"id":"oMubBu4Y0Pjx"},"id":"oMubBu4Y0Pjx","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Re-initialize X_train, X_test, y_train, y_test and scaled versions\n","# to ensure consistent state for each run of this cell.\n","# This ensures y_train and y_test start as 1-indexed Series from `y`.\n","# Assuming X and y are already defined from previous cells.\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.25, random_state=42, stratify=y\n",")\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","results = []\n","\n","for name, model in models.items():\n","    current_y_train_for_model = y_train  # Start with the original Series\n","    current_y_test_for_model = y_test    # Start with the original Series\n","\n","    # Temporarily adjust y_train and y_test to be 0-indexed for XGBoost\n","    if name == \"XGBoost\":\n","        # Convert y_train and y_test to NumPy arrays and ensure 0-indexing\n","        # Assuming original_y_train is 1-indexed (1-7), subtract 1.\n","        # This will correctly transform [1,2,..,7] to [0,1,..,6]\n","        current_y_train_for_model = (y_train - 1).values\n","        current_y_test_for_model = (y_test - 1).values\n","\n","    if name in [\"Logistic Regression\", \"KNN\"]:\n","        res = evaluate_model(name, model, X_train_scaled, X_test_scaled, current_y_train_for_model, current_y_test_for_model)\n","    else:\n","        # Ensure X_train and X_test are passed directly for models that don't need scaling\n","        res = evaluate_model(name, model, X_train, X_test, current_y_train_for_model, current_y_test_for_model)\n","\n","    results.append(res)\n","\n","columns = [\"Model\", \"Accuracy\", \"AUC\", \"Precision\", \"Recall\", \"F1 Score\", \"MCC\"]\n","results_df = pd.DataFrame(results, columns=columns)\n","#results_df\n","results_df.to_csv(\"/content/drive/MyDrive/Colab Notebooks/model_comparison_results_sample.csv\", index=False)"],"metadata":{"id":"PQ5BQWXl0RvL"},"id":"PQ5BQWXl0RvL","execution_count":null,"outputs":[]},{"cell_type":"code","source":["rf_model = models[\"Random Forest\"]\n","rf_model.fit(X_train, y_train)\n","\n","importances = pd.Series(rf_model.feature_importances_, index=X.columns)\n","importances.sort_values(ascending=False).head(15)\n","\n"],"metadata":{"id":"7e1tde1r0W8u"},"id":"7e1tde1r0W8u","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model Performance Observations\n","\n","| Model | Observation |\n","|-------|-------------|\n","| Logistic Regression | |\n","| Decision Tree | |\n","| KNN | |\n","| Naive Bayes | |\n","| Random Forest | |\n","| XGBoost | |"],"metadata":{"id":"gZbA_8VF3n1w"},"id":"gZbA_8VF3n1w"},{"cell_type":"code","source":["\n"],"metadata":{"id":"Tyaf5Yww0eCd"},"execution_count":null,"outputs":[],"id":"Tyaf5Yww0eCd"},{"cell_type":"markdown","id":"7cedd478","metadata":{"id":"7cedd478"},"source":["\n","## Key Insights\n","1. Dataset contains no missing values.\n","2. Cover_Type is imbalanced.\n","3. Elevation shows separation among classes.\n","4. Some distance features are skewed.\n","5. Correlation exists among several variables.\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1V9pFgGL0CqLquoKbIigUoyBsynTO-0k-","timestamp":1771070512092}],"private_outputs":true},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}