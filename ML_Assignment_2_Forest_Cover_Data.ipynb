{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0876b8da",
      "metadata": {
        "id": "0876b8da"
      },
      "source": [
        "# Final Exploratory Data Analysis (EDA)\n",
        "Dataset: covtype.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YS474DzxT0Ms",
      "metadata": {
        "id": "YS474DzxT0Ms"
      },
      "outputs": [],
      "source": [
        "# Google Colab mount - skipped for local execution\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "f54Zu1y-9Flu"
      },
      "id": "f54Zu1y-9Flu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa333f97",
      "metadata": {
        "id": "fa333f97"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "plt.style.use(\"default\")\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/covtype.csv\")\n",
        "df.head()\n",
        "df=df.head(100000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1577feaf",
      "metadata": {
        "id": "1577feaf"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6522d357",
      "metadata": {
        "collapsed": true,
        "id": "6522d357"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ae25919",
      "metadata": {
        "collapsed": true,
        "id": "8ae25919"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "282aae55",
      "metadata": {
        "collapsed": true,
        "id": "282aae55"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "033332bc",
      "metadata": {
        "id": "033332bc"
      },
      "outputs": [],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97a10be4",
      "metadata": {
        "id": "97a10be4"
      },
      "outputs": [],
      "source": [
        "\n",
        "df = df.drop_duplicates()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97914cce",
      "metadata": {
        "collapsed": true,
        "id": "97914cce"
      },
      "outputs": [],
      "source": [
        "\n",
        "df[\"Cover_Type\"].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a24f7184",
      "metadata": {
        "id": "a24f7184"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x=\"Cover_Type\", data=df)\n",
        "plt.title(\"Distribution of Cover Types\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a1475c5",
      "metadata": {
        "id": "6a1475c5"
      },
      "outputs": [],
      "source": [
        "\n",
        "num_cols = df.select_dtypes(include=np.number).columns\n",
        "df[num_cols].hist(figsize=(15,12), bins=30)\n",
        "plt.suptitle(\"Histogram of Numerical Features\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bba1641a",
      "metadata": {
        "id": "bba1641a"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.figure(figsize=(14,10))\n",
        "corr = df.corr()\n",
        "sns.heatmap(corr, cmap=\"coolwarm\", linewidths=0.5)\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "788c061c",
      "metadata": {
        "id": "788c061c"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.boxplot(x=\"Cover_Type\", y=\"Elevation\", data=df)\n",
        "plt.title(\"Elevation vs Cover Type\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zvtxqyYUUzul",
      "metadata": {
        "id": "zvtxqyYUUzul"
      },
      "outputs": [],
      "source": [
        "corr_with_target = df.corr()[\"Cover_Type\"].sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "corr_with_target.drop(\"Cover_Type\").plot(kind=\"bar\")\n",
        "plt.title(\"Correlation of Features with Cover_Type\")\n",
        "plt.ylabel(\"Correlation value\")\n",
        "plt.xlabel(\"Features\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qWzzjyxAVDcs",
      "metadata": {
        "id": "qWzzjyxAVDcs"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,10))\n",
        "sns.heatmap(df.corr()[[\"Cover_Type\"]], annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Correlation of Features with Cover_Type\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j4P-l7-4dQoI",
      "metadata": {
        "id": "j4P-l7-4dQoI"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def basic_info(df):\n",
        "    print(df.info())\n",
        "    print(df.describe())\n",
        "\n",
        "def check_missing(df):\n",
        "    print(df.isnull().sum())\n",
        "\n",
        "def plot_target_distribution(df, target):\n",
        "    sns.countplot(x=target, data=df)\n",
        "    plt.title(\"Target Distribution\")\n",
        "    plt.show()\n",
        "\n",
        "def correlation_plot(df):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.heatmap(df.corr(), cmap=\"coolwarm\", annot=False)\n",
        "    plt.title(\"Correlation Heatmap\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LHeOVUF3ruRE",
      "metadata": {
        "id": "LHeOVUF3ruRE"
      },
      "outputs": [],
      "source": [
        "\n",
        "def numerical_summary(df):\n",
        "    num_df = df.select_dtypes(include=np.number)\n",
        "    return num_df.describe()\n",
        "\n",
        "def categorical_summary(df):\n",
        "    cat_df = df.select_dtypes(exclude=np.number)\n",
        "    return cat_df.describe()\n",
        "\n",
        "def skewness(df):\n",
        "    return df.select_dtypes(include=np.number).skew()\n",
        "def target_distribution(df, target):\n",
        "    print(df[target].value_counts())\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sns.countplot(x=df[target])\n",
        "    plt.title(\"Target Distribution\")\n",
        "    plt.show()\n",
        "def boxplots(df):\n",
        "    num_cols = df.select_dtypes(include=np.number).columns\n",
        "    for col in num_cols:\n",
        "        plt.figure(figsize=(5,3))\n",
        "        sns.boxplot(x=df[col])\n",
        "        plt.title(col)\n",
        "        sns.despine()\n",
        "        plt.show()\n",
        "def binary_feature_counts(df, columns, title):\n",
        "    counts = df[columns].sum().sort_values(ascending=False)\n",
        "    plt.figure(figsize=(10,5))\n",
        "    counts.plot(kind=\"bar\")\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "    return counts\n",
        "#binary_feature_counts(data, wilderness_cols, \"Wilderness Area Count\")\n",
        "#binary_feature_counts(data, soil_cols, \"Soil Type Count\")\n",
        "def violin_plots(df, features, target):\n",
        "    for col in features:\n",
        "        plt.figure(figsize=(6,4))\n",
        "        sns.violinplot(x=target, y=col, data=df)\n",
        "        plt.title(col)\n",
        "        plt.show()\n",
        "\n",
        "def violin(data):\n",
        "  # plot bg\n",
        "  # Extracting all numerical features from data\n",
        "  num_fea = data.iloc[:, :10]\n",
        "\n",
        "  # extracting all binary features from data\n",
        "  binary_fea = data.iloc[:, 10:-1]\n",
        "\n",
        "  # Splitting\n",
        "  Wild_data, Soil_data = binary_fea.iloc[:,:4], binary_fea.iloc[:,4:]\n",
        "  sns.set_style(\"darkgrid\", {'grid.color': '.1'})\n",
        "\n",
        "  # setting target variable\n",
        "  target = data['Cover_Type']\n",
        "  # features to be compared with target variable\n",
        "  features = Wild_data.columns\n",
        "\n",
        "\n",
        "  # loop for plotting Violin Plot for each features in the data\n",
        "  for i in range(0, len(features)):\n",
        "\n",
        "      #figure size\n",
        "      plt.subplots(figsize=(13, 9))\n",
        "\n",
        "      # Plot violin for i feature for every class in target\n",
        "      sns.violinplot(data = Wild_data, x=target, y = features[i])\n",
        "\n",
        "      # x-axis label size\n",
        "      plt.xticks(size = 15)\n",
        "      # y-axis label size\n",
        "      plt.yticks(size = 16)\n",
        "\n",
        "      # Horizontal axis Label\n",
        "      plt.xlabel('Forest Cover Types', size = 17)\n",
        "      # Vertical axis Label\n",
        "      plt.ylabel(features[i], size = 17)\n",
        "\n",
        "      # display plot\n",
        "      plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lMOkPhozulKC",
      "metadata": {
        "id": "lMOkPhozulKC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G7TqbVcmr_1c",
      "metadata": {
        "id": "G7TqbVcmr_1c"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def feature_importance(df, target, model=None):\n",
        "    X = df.drop(target, axis=1)\n",
        "    y = df[target]\n",
        "\n",
        "    if model is None:\n",
        "        model = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
        "\n",
        "    model.fit(X, y)\n",
        "    imp = pd.DataFrame({\n",
        "        \"Feature\": X.columns,\n",
        "        \"Importance\": model.feature_importances_\n",
        "    }).sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "    return imp\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7U7nXWp2sH7u",
      "metadata": {
        "id": "7U7nXWp2sH7u"
      },
      "outputs": [],
      "source": [
        "data=df\n",
        "\n",
        "numerical_summary(data)\n",
        "\n",
        "skewness(data)\n",
        "\n",
        "target_distribution(data, \"Cover_Type\")\n",
        "\n",
        "boxplots(data)\n",
        "\n",
        "#importance = feature_importance(data, \"Cover_Type\")\n",
        "#importance.head(10)\n",
        "\n",
        "#violin_plots(df, features, target)\n",
        "violin(df)\n",
        "'''\n",
        "X_train, X_test, y_train, y_test = scale_and_split(data, \"Cover_Type\")\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model_evaluation(RandomForestClassifier(n_jobs=-1), X_train, X_test, y_train, y_test)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-EwDWEX8tNr-",
      "metadata": {
        "id": "-EwDWEX8tNr-"
      },
      "outputs": [],
      "source": [
        "\n",
        "# importing model for feature importance\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "# passing the model\n",
        "model = ExtraTreesClassifier(random_state = 53)\n",
        "\n",
        "# feeding all our features to var 'X'\n",
        "X = df.iloc[:,:-1]\n",
        "# feeding our target variable to var 'y'\n",
        "y = df['Cover_Type']\n",
        "\n",
        "# training the model\n",
        "model.fit(X, y)\n",
        "\n",
        "# extracting feature importance from model and making a dataframe of it in descending order\n",
        "ETC_feature_importances = pd.DataFrame(model.feature_importances_, index = X.columns, columns=['ETC']).sort_values('ETC', ascending=False)\n",
        "\n",
        "# removing traces of this model\n",
        "model = None\n",
        "\n",
        "# show top 10 features\n",
        "ETC_feature_importances.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pIky_8yztcjX",
      "metadata": {
        "id": "pIky_8yztcjX"
      },
      "outputs": [],
      "source": [
        "# importing model for feature importance\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# passing the model\n",
        "model = RandomForestClassifier(random_state = 53)\n",
        "\n",
        "# training the model\n",
        "model.fit(X, y)\n",
        "\n",
        "# extracting feature importance from model and making a dataframe of it in descending order\n",
        "RFC_feature_importances = pd.DataFrame(model.feature_importances_, index = X.columns, columns=['RFC']).sort_values('RFC', ascending=False)\n",
        "\n",
        "# removing traces of this model\n",
        "model = None\n",
        "\n",
        "# show top 10 features\n",
        "RFC_feature_importances.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qz37WNfdtfkm",
      "metadata": {
        "id": "qz37WNfdtfkm"
      },
      "outputs": [],
      "source": [
        "\n",
        "# importing model for feature importance\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# passing the model\n",
        "model = AdaBoostClassifier(random_state = 53)\n",
        "\n",
        "model.fit(X, y)\n",
        "\n",
        "# extracting feature importance from model and making a dataframe of it in descending order\n",
        "ADB_feature_importances = pd.DataFrame(model.feature_importances_, index = X.columns, columns=['ADB']).sort_values('ADB', ascending=False)\n",
        "\n",
        "# removing traces of this model\n",
        "model = None\n",
        "\n",
        "ADB_feature_importances.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ayMYBKyktjiO",
      "metadata": {
        "id": "ayMYBKyktjiO"
      },
      "outputs": [],
      "source": [
        "\n",
        "# importing model for feature importance\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# passing the model\n",
        "model = GradientBoostingClassifier(random_state = 53)\n",
        "\n",
        "# training the model\n",
        "model.fit(X, y)\n",
        "\n",
        "# extracting feature importance from model and making a dataframe of it in descending order\n",
        "GBC_feature_importances = pd.DataFrame(model.feature_importances_, index = X.columns, columns=['GBC']).sort_values('GBC', ascending=False)\n",
        "\n",
        "# removing traces of this model\n",
        "model = None\n",
        "\n",
        "# show top 10 features\n",
        "GBC_feature_importances.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dEz6Bbv2ymkq",
      "metadata": {
        "id": "dEz6Bbv2ymkq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# feeding sample features to var 'X'\n",
        "#X = sample.iloc[:,:-1]\n",
        "# feeding our target variable to var 'y'\n",
        "#y = sample['Cover_Type']\n",
        "\n",
        "#df = df[['Elevation','Horizontal_Distance_To_Roadways','Horizontal_Distance_To_Fire_Points','Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology','Aspect','Wilderness_Area4',\n",
        "#            'Hillshade_Noon','Hillshade_3pm','Hillshade_9am','Slope','Soil_Type22','Soil_Type10','Soil_Type4','Soil_Type34','Wilderness_Area3','Soil_Type12',\n",
        "#            'Soil_Type2','Wilderness_Area1', 'Cover_Type']]\n",
        "\n",
        "X = df.drop(\"Cover_Type\", axis=1)\n",
        "y = df[\"Cover_Type\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42, stratify=y\n",
        ")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Train shape:\", X_train.shape)\n",
        "print(\"Test shape:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Hk_aplHe0KpW",
      "metadata": {
        "id": "Hk_aplHe0KpW"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, matthews_corrcoef, roc_auc_score,\n",
        "    confusion_matrix, classification_report\n",
        ")\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=2000, n_jobs=-1),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
        "    \"XGBoost\": XGBClassifier(\n",
        "        objective=\"multi:softprob\",\n",
        "        num_class=len(y.unique()),\n",
        "        eval_metric=\"mlogloss\",\n",
        "        random_state=42,\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1\n",
        "    )\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oMubBu4Y0Pjx",
      "metadata": {
        "id": "oMubBu4Y0Pjx"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(name, model, Xtr, Xte, ytr, yte):\n",
        "    model.fit(Xtr, ytr)\n",
        "    y_pred = model.predict(Xte)\n",
        "    y_prob = model.predict_proba(Xte)\n",
        "\n",
        "    acc = accuracy_score(yte, y_pred)\n",
        "    prec = precision_score(yte, y_pred, average=\"weighted\")\n",
        "    rec = recall_score(yte, y_pred, average=\"weighted\")\n",
        "    f1 = f1_score(yte, y_pred, average=\"weighted\")\n",
        "    mcc = matthews_corrcoef(yte, y_pred)\n",
        "    auc = roc_auc_score(yte, y_prob, multi_class=\"ovr\")\n",
        "\n",
        "    print(f\"\\n{name}\")\n",
        "    print(classification_report(yte, y_pred))\n",
        "\n",
        "    '''\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sns.heatmap(cm, annot=False, cmap=\"Blues\")\n",
        "    plt.title(f\"Confusion Matrix - {name}\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.show()\n",
        "    '''\n",
        "    return [name, acc, auc, prec, rec, f1, mcc]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "# Corrected: Create the full directory path\n",
        "os.makedirs(\"/content/drive/MyDrive/Colab Notebooks/models\", exist_ok=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ✅ save scaler\n",
        "joblib.dump(scaler, \"/content/drive/MyDrive/Colab Notebooks/models/scaler.pkl\")\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    current_y_train_for_model = y_train\n",
        "    current_y_test_for_model = y_test\n",
        "    current_X_train_for_model = X_train\n",
        "    current_X_test_for_model = X_test\n",
        "\n",
        "    if name == \"XGBoost\":\n",
        "        current_y_train_for_model = (y_train - 1).values\n",
        "        current_y_test_for_model = (y_test - 1).values\n",
        "        current_X_train_for_model = np.ascontiguousarray(X_train_scaled)\n",
        "        current_X_test_for_model = np.ascontiguousarray(X_test_scaled)\n",
        "\n",
        "        res = evaluate_model(\n",
        "            name, model,\n",
        "            current_X_train_for_model, current_X_test_for_model,\n",
        "            current_y_train_for_model, current_y_test_for_model\n",
        "        )\n",
        "\n",
        "        # ✅ save XGBoost model\n",
        "        joblib.dump(model, \"/content/drive/MyDrive/Colab Notebooks/models/xgboost_model.pkl\")\n",
        "\n",
        "    elif name in [\"Logistic Regression\", \"KNN\"]:\n",
        "        res = evaluate_model(\n",
        "            name, model,\n",
        "            X_train_scaled, X_test_scaled,\n",
        "            current_y_train_for_model, current_y_test_for_model\n",
        "        )\n",
        "\n",
        "        # ✅ save scaled-data models\n",
        "        fname = name.replace(\" \", \"_\").lower() + \"_model.pkl\"\n",
        "        joblib.dump(model, f\"/content/drive/MyDrive/Colab Notebooks/models/{fname}\")\n",
        "\n",
        "    else:\n",
        "        res = evaluate_model(\n",
        "            name, model,\n",
        "            X_train, X_test,\n",
        "            current_y_train_for_model, current_y_test_for_model\n",
        "        )\n",
        "\n",
        "        # ✅ save unscaled-data models\n",
        "        fname = name.replace(\" \", \"_\").lower() + \"_model.pkl\"\n",
        "        joblib.dump(model, f\"/content/drive/MyDrive/Colab Notebooks/models/{fname}\")\n",
        "\n",
        "    results.append(res)\n",
        "\n",
        "columns = [\"Model\", \"Accuracy\", \"AUC\", \"Precision\", \"Recall\", \"F1 Score\", \"MCC\"]\n",
        "results_df = pd.DataFrame(results, columns=columns)\n",
        "results_count=df[\"Cover_Type\"].value_counts()\n",
        "results_df.to_csv(\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/model_comparison_results_100000.csv\",\n",
        "    index=False\n",
        ")\n",
        "# Append results_count\n",
        "results_count.to_csv(\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/model_comparison_results_100000.csv\",\n",
        "    mode=\"a\",\n",
        "    header=False,   # already written above\n",
        "    index=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "DUrDIV92NZB3"
      },
      "id": "DUrDIV92NZB3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "gZbA_8VF3n1w",
      "metadata": {
        "id": "gZbA_8VF3n1w"
      },
      "source": [
        "## Model Performance Observations\n",
        "\n",
        "| Model | Observation |\n",
        "|-------|-------------|\n",
        "| Logistic Regression | |\n",
        "| Decision Tree | |\n",
        "| KNN | |\n",
        "| Naive Bayes | |\n",
        "| Random Forest | |\n",
        "| XGBoost | |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Tyaf5Yww0eCd",
      "metadata": {
        "id": "Tyaf5Yww0eCd"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cedd478",
      "metadata": {
        "id": "7cedd478"
      },
      "source": [
        "\n",
        "## Key Insights\n",
        "1. Dataset contains no missing values.\n",
        "2. Cover_Type is imbalanced.\n",
        "3. Elevation shows separation among classes.\n",
        "4. Some distance features are skewed.\n",
        "5. Correlation exists among several variables.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}